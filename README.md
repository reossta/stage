# Solution D√©cisionnelle pour le Reporting de la Scolarit√© Universitaire

## üéì Contexte et Objectif

Ce d√©p√¥t GitHub contient les livrables cl√©s du projet de stage r√©alis√© √† la DSI de l'*Universit√© ESPRIT*, ax√© sur la *Mise en place d'une solution d√©cisionnelle* pour l'analyse des donn√©es de scolarit√©.

L'objectif principal est de cr√©er une architecture *Business Intelligence (BI)* compl√®te pour transformer les donn√©es transactionnelles (OLTP) en un r√©f√©rentiel analytique *(OLAP)* fiable. Ceci permet le pilotage strat√©gique de la performance acad√©mique via une analyse multidimensionnelle.

## ‚öôÔ∏è Stack Technologique et Mod√©lisation

| Domaine | Outil / Technologie | R√¥le dans le Projet |
| :--- | :--- | :--- |
| *Mod√©lisation DW* | *PostgreSQL* | Base de donn√©es cible (Data Warehouse) mod√©lis√©e en *Sch√©ma en √âtoile*. |
| *ETL* | *Pentaho Data Integration (PDI)* | Conception des flux de transformation et d'alimentation du DW. |
| *Reporting* | *Microsoft Power BI Desktop* | Cr√©ation des tableaux de bord interactifs et des mesures DAX. |
| *Mod√®le* | *Sch√©ma en √âtoile* | Centr√© sur la table de faits fact_reporting (voir Model_en_etoile.png). |

## ‚ú® Livrables Cl√©s et Fichiers

| Fichier / Dossier | Description |
| :--- | :--- |
| **Rapport_Stage_NesrineBousselmi.pdf**| Le rapport de stage final d√©taillant l'analyse, la m√©thodologie et l'impl√©mentation compl√®te. |
| **Model_en_etoile.png** | Capture d'√©cran illustrant la *mod√©lisation dimensionnelle* du Data Warehouse (PostgreSQL). |
| **job_ETL_Pentaho.png** | Capture d'√©cran du *Job ETL ma√Ætre* orchestrant le processus de chargement. |
| **transformation_1.ktr** | Fichier de transformation Pentaho PDI (.ktr) contenant les √©tapes d√©taill√©es de nettoyage et de chargement des donn√©es. |
| **Stage_dashboard.pbix** | Fichier Power BI (.pbix) contenant le mod√®le de donn√©es interne, les mesures DAX, et les *tableaux de bord interactifs finaux*. |
| **01_Scripts_SQL/** | (Dossier √† cr√©er) Contient les scripts SQL de cr√©ation des tables du Data Warehouse. |

## üöÄ Guide de D√©marrage et Reproduction

Pour r√©pliquer l'environnement de travail et visualiser la solution :

1.  *Base de Donn√©es :* Assurez-vous d'avoir une instance *PostgreSQL* op√©rationnelle. Cr√©ez la structure du Data Warehouse en utilisant les scripts SQL (si disponibles) ou en vous r√©f√©rant √† l'image **Model_en_etoile.png**.
2.  *Pr√©paration ETL :* Ouvrez les fichiers **.ktr** et **.kjb** dans Pentaho Data Integration. V√©rifiez et mettez √† jour les connexions aux bases de donn√©es sources et cibles dans l'outil.
3.  *Ex√©cution :* Ex√©cutez le Job ETL Pentaho (voir **job_ETL_Pentaho.png**) pour alimenter le Data Warehouse.
4.  *Reporting :* Ouvrez le fichier **Stage_dashboard.pbix** avec Power BI Desktop. Mettez √† jour la source de donn√©es pour pointer vers votre base PostgreSQL locale et rafra√Æchissez le rapport.

---

## üìû Contact

* *Nom :* Yosra Challekh
* *Email :* yosra.challekh@esprit.tn

